<resourceInfo xmlns="http://www.meta-share.org/META-SHARE_XMLSchema" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.meta-share.org/META-SHARE_XMLSchema http://www.meta-share.org/META-SHARE_XMLSchema/v3.1/META-SHARE-Resource.xsd">
   <identificationInfo>
      <resourceName lang="en">Laboratory Conditions Czech Audio-Visual Speech Corpus</resourceName>
      <resourceName lang="fr">Corpus tch&#232;que audio-visuel enregistr&#233; en conditions de laboratoire</resourceName>
      <description lang="en">This is an audio-visual speech database for training and testing of Czech audio-visual continuous speech recognition systems. The corpus consists of about 25 hours of audio-visual records of 65 speakers in laboratory conditions. Data collection was done with static illumination, and recorded subjects were instructed to remain static.The average speaker age was 22 years old. Speakers were asked to read 200 sentences each (50 common for all speakers and 150 specific to each speaker). The average total length of recording per speaker is 23 minutes.All audio-visual data are transcribed (.trs files) and divided into sentences (one sentence per file). For each video file we get the description file containing information about the position and size of the region of interest.Acoustic data are stored in wave files using PCM format, sampling frequency 44kHz, resolution 16 bits. Each speaker&#8217;s acoustic data set represents about 140 MB of disk space (about 9 GB as a whole).Visual data are stored in video files (.avi format) using the digital video (DV) codec. Visual data per speaker take about 3 GB of disk (about 195 GB as a whole) and are stored on an IDE hard disk (NTFS format).</description>
      <description lang="fr">Cette base de donn&#233;es audio-visuelle a &#233;t&#233; constitu&#233;e pour entra&#238;ner et tester les syst&#232;mes de reconnaissance audio-visuelle en langue tch&#232;que. Le corpus comprend environ 25 heures d&#8217;enregistrements audio-visuels de 65 locuteurs enregistr&#233;s en conditions de laboratoire. La collecte des donn&#233;es a &#233;t&#233; r&#233;alis&#233;e par &#233;clairage statique. On a donc demand&#233; aux sujets enregistr&#233;s de rester en position statique.La moyenne d&#8217;&#226;ge des locuteurs est de 22 ans. On a demand&#233; aux locuteurs de lire 200 phrases chacun (50 en commun pour tous les locuteurs et 150 sp&#233;cifiques &#224; chaque locuteur). La dur&#233;e moyenne totale d&#8217;enregistrement par locuteur est de 23 minutes.Toutes les donn&#233;es audio-visuelles ont &#233;t&#233; transcrites (.trs files) et d&#233;coup&#233;es par phrases (une phrase par fichier). A chaque fichier vid&#233;o correspond un fichier de description contenant l&#8217;information sur la position et la taille de la r&#233;gion d&#8217;int&#233;r&#234;t.Les donn&#233;es acoustiques ont &#233;t&#233; stock&#233;es en fichiers wave en utilisant le format PCM, une fr&#233;quence d&#8217;&#233;chantillonnage de 44kHz et une r&#233;solution de 16 bits. Un ensemble de donn&#233;es acoustiques pour chaque locuteur repr&#233;sente environ 140 Mo d&#8217;espace-disque (environ 9 Go en totalit&#233;).Les donn&#233;es visuelles sont stock&#233;es en fichiers vid&#233;o (format .avi) utilisant le codec vid&#233;o num&#233;rique DV. Les donn&#233;es visuelles par locuteur prennent environ 3 Go de disque (environ 195 Go en totalit&#233;) et sont stock&#233;es sur un disque dur IDE au format NTFS.</description>
      <resourceShortName>UWB-05-LCAVC</resourceShortName>
      <url>http://catalog.elra.info/product_info.php?products_id=1081</url>
      <metaShareId>NOT_DEFINED_FOR_V2</metaShareId>
      <identifier>ELRA-S0283</identifier>
   </identificationInfo><distributionInfo><availability>available</availability><licenceInfo>
         <licence>ELRA_VAR</licence>
         <restrictionsOfUse>commercialUse</restrictionsOfUse>
         </licenceInfo>
      <fee>2050.00</fee>
         <userNature>academic</userNature>
         <membershipInfo>
            <member>true</member>
            <membershipInstitution>ELRA</membershipInstitution>
         </membershipInfo>
      <availabilityStartDate>2008-11-05</availabilityStartDate>
   </distributionInfo><distributionInfo><availability>available</availability><licenceInfo>
         <licence>ELRA_END_USER</licence>
         <restrictionsOfUse>nonCommercialUse</restrictionsOfUse>
         </licenceInfo>
      <fee>550.00</fee>
         <userNature>academic</userNature>
         <membershipInfo>
            <member>true</member>
            <membershipInstitution>ELRA</membershipInstitution>
         </membershipInfo>
      </distributionInfo><distributionInfo><availability>available</availability><licenceInfo>
         <licence>ELRA_VAR</licence>
         <restrictionsOfUse>commercialUse</restrictionsOfUse>
         </licenceInfo>
      <fee>2050.00</fee>
         <userNature>commercial</userNature>
         <membershipInfo>
            <member>true</member>
            <membershipInstitution>ELRA</membershipInstitution>
         </membershipInfo>
      </distributionInfo><distributionInfo><availability>available</availability><licenceInfo>
         <licence>ELRA_END_USER</licence>
         <restrictionsOfUse>nonCommercialUse</restrictionsOfUse>
         </licenceInfo>
      <fee>550.00</fee>
         <userNature>commercial</userNature>
         <membershipInfo>
            <member>true</member>
            <membershipInstitution>ELRA</membershipInstitution>
         </membershipInfo>
      </distributionInfo><distributionInfo><availability>available</availability><licenceInfo>
         <licence>ELRA_VAR</licence>
         <restrictionsOfUse>commercialUse</restrictionsOfUse>
         </licenceInfo>
      <fee>3050.00</fee>
         <userNature>academic</userNature>
         <membershipInfo>
            <member>false</member>
            <membershipInstitution>ELRA</membershipInstitution>
         </membershipInfo>
      </distributionInfo><distributionInfo><availability>available</availability><licenceInfo>
         <licence>ELRA_END_USER</licence>
         <restrictionsOfUse>nonCommercialUse</restrictionsOfUse>
         </licenceInfo>
      <fee>1050.00</fee>
         <userNature>academic</userNature>
         <membershipInfo>
            <member>false</member>
            <membershipInstitution>ELRA</membershipInstitution>
         </membershipInfo>
      </distributionInfo><distributionInfo><availability>available</availability><licenceInfo>
         <licence>ELRA_VAR</licence>
         <restrictionsOfUse>commercialUse</restrictionsOfUse>
         </licenceInfo>
      <fee>3050.00</fee>
         <userNature>commercial</userNature>
         <membershipInfo>
            <member>false</member>
            <membershipInstitution>ELRA</membershipInstitution>
         </membershipInfo>
      </distributionInfo><distributionInfo><availability>available</availability><licenceInfo>
         <licence>ELRA_END_USER</licence>
         <restrictionsOfUse>nonCommercialUse</restrictionsOfUse>
         </licenceInfo>
      <fee>1050.00</fee>
         <userNature>commercial</userNature>
         <membershipInfo>
            <member>false</member>
            <membershipInstitution>ELRA</membershipInstitution>
         </membershipInfo>
      </distributionInfo>
   <contactPerson>
      <surname>Val&#233;rie</surname>
      <givenName>Mapelli</givenName>
      <communicationInfo>
         <email>mapelli@elda.org</email>
         <url>http://www.elda.org</url>
         <address>55-57 rue Brillat-Savarin</address>
         <zipCode>75013</zipCode>
         <city>Paris</city>
         <country>France</country>
         <telephoneNumber>+1 43 13 33 33</telephoneNumber>
         <faxNumber>+1 43 14 33 30</faxNumber>
      </communicationInfo>
   </contactPerson>
   <metadataInfo>
      <metadataCreationDate>2005-05-12</metadataCreationDate>
   </metadataInfo>
   <versionInfo>
      <version>1.0</version>
      <lastDateUpdated>2008-11-05</lastDateUpdated>
   </versionInfo>
   <usageInfo>
      <actualUseInfo>
         <actualUse>nlpApplications</actualUse>
         <useNLPSpecific>speechRecognition</useNLPSpecific>
      </actualUseInfo>
   </usageInfo>
   <resourceComponentType>
      <corpusInfo>
         <resourceType>corpus</resourceType>
         <corpusMediaType>
            <corpusAudioInfo>
               <mediaType>audio</mediaType>
               <lingualityInfo>
                  <lingualityType>monolingual</lingualityType>
               </lingualityInfo>
               <languageInfo>
                  <languageId>cze/ces</languageId>
                  <languageName>Czech</languageName>
               </languageInfo>
               <audioSizeInfo>
                  <sizeInfo>
                     <size>no size available</size>
                     <sizeUnit>items</sizeUnit>
                  </sizeInfo>
               </audioSizeInfo>
            </corpusAudioInfo>
            <corpusVideoInfo>
               <mediaType>video</mediaType>
               <lingualityInfo>
                  <lingualityType>monolingual</lingualityType>
               </lingualityInfo>
               <languageInfo>
                  <languageId>cze/ces</languageId>
                  <languageName>Czech</languageName>
               </languageInfo>
               <sizeInfo>
                  <size>no size available</size>
                  <sizeUnit>items</sizeUnit>
               </sizeInfo>
            </corpusVideoInfo>
         </corpusMediaType>
      </corpusInfo>
   </resourceComponentType>
</resourceInfo>
